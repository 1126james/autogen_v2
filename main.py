# Somehow in mac, it cant find local packages
# Run this to solve no local modules found in mac
import os
import sys

# Get the project root directory (assuming your notebook is in a subdirectory)
project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))
if project_root not in sys.path:
    sys.path.append(project_root)


# Python lib
import asyncio
import os
import argparse

# Autogen-0.4
from autogen_agentchat.agents import AssistantAgent

from autogen_agentchat.messages import TextMessage
from autogen_ext.models.openai import OpenAIChatCompletionClient

# Local
from utils import get_columns_sample, initialize_individual_chat, jsonify_prompt, Spinner
from prompts import data_dict_summarizer_prompt

# Only edit here AND filepath under if __name__ == "__main__":
data_dict_summarizer = "qwen2.5:32b-instruct-q8_0-32768"
data_dict_generator = "qwen2.5:32b-instruct-q8_0"

# Common config
llm_base_url = "http://34.204.63.234:11434/v1"
api_key = "none"
model_info =  {
        "vision": False,
        "function_calling": False,
        "json_output": True,
        "family": "Qwen2.5"
    }

# Create reasoning config
# Need to be more creative
data_dict_summarizer_client = OpenAIChatCompletionClient(
    frequency_penalty=0.2, 
    logit_bias=None, 
    max_tokens=128000,
    presence_penalty=0.5, 
    response_format={"type": "json_object"}, 
    seed=42, 
    temperature=0.8, 
    top_p=0.95, 
    model=data_dict_summarizer,
    api_key='none',  
    model_info=model_info, 
    base_url='http://34.204.63.234:11434/v1'
    )

# Just generate the data dict based on obervered facts
data_dict_generator_client = OpenAIChatCompletionClient(
    frequency_penalty=0.4, 
    logit_bias=None, 
    max_tokens=2048, 
    presence_penalty=0.3, 
    response_format={"type": "json_object"},
    seed=42, 
    temperature=0.2, 
    top_p=0.7, 
    model=data_dict_generator,
    api_key='none', 
    model_info=model_info, 
    base_url='http://34.204.63.234:11434/v1')



#######################################################################
#   !!! DONT EDIT BELOW EXCEPT FOR if __name__ == "__main__":   !!!   #
#######################################################################
async def main(results: list):
    try:
        # Create spinner instance
        spinner = Spinner(f"Populating {len(results)} data dictionaries...")
        spinner.start()

        # assign each file (task) for each agent
        tasks = [initialize_individual_chat(filename=results[index][0], metadata=results[index][1], data_dict_generator_client=data_dict_generator_client) for index in range(len(results))]

        # Execute all agent chat tasks concurrently, depends on ollama queue
        responses = await asyncio.gather(*tasks)

    finally:
        spinner.stop()

    # Convert the responses to list of json responses
    generated_data_dict, log_file_name = await jsonify_prompt(responses)

    # Combine json responses with an initial task message
    # initial_task = [TextMessage(content=f"Review the data dictionary generated by the file handling agents.",source="user")]
    # generated_data_dict.extend(initial_task)

    try:
        # Create spinner instance
        spinner = Spinner(f"Generating analytics use cases...")
        spinner.start()

    # Initialize summarizer agent
        final_agent = AssistantAgent(name="Data_Dictionary_Analytics_Suggester",
                                     model_client=data_dict_summarizer_client,
                                     system_message=data_dict_summarizer_prompt()
        )

        generated_use_cases = await final_agent.on_messages(
                [TextMessage(content=f"{generated_data_dict}\n\nReview the above data dictionary.",source="user")], None
            )
        
        # Append suggestions into the created log file
        # To-do: remove the first "{" after generating use cases, or just add the json obj to the dict in log
        with open(log_file_name, "a") as f:
            f.write("\n\n"+generated_use_cases.chat_message.content)
            f.write('}')

        print("\nOperation completed.")
        print(f"Analytics use cases appended to {log_file_name}.")

    finally:
        spinner.stop()
    return generated_data_dict, generated_use_cases.chat_message.content, log_file_name


if __name__ == "__main__":
    # Set up command line argument parsing
    parser = argparse.ArgumentParser(description='Process files from a specified directory.')
    parser.add_argument('root_path', nargs='?', default='sheets/mysql/', 
                       help='Root path for processing files (default: sheets/mysql/)')
    args = parser.parse_args()

    async def run():
        root = args.root_path
        # Get all filenames that should be processed in the directory
        files: list[str] = os.listdir(path=root)
        
        # Create and run a list of tasks to process each file
        tasks = [get_columns_sample(root, file) for file in files]
        results = await asyncio.gather(*tasks)

        # Combine the results with the filenames
        results = list(zip(files, results))
        
        # Run the main function
        return await main(results)
    
    generated_data_dict, generated_use_cases, log_file_name = asyncio.run(run())
