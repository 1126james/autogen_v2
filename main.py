# Somehow in mac, it cant find local packages
# Run this to solve no local modules found in mac
import os
import sys

# Get the project root directory (assuming your notebook is in a subdirectory)
project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))
if project_root not in sys.path:
    sys.path.append(project_root)


# Python lib
import asyncio
import os
import json
import argparse

# Autogen-0.4
from autogen_agentchat.agents import AssistantAgent

from autogen_agentchat.messages import TextMessage
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.models.openai.config import OpenAIClientConfigurationConfigModel

# Local
from utils import get_dataset_profile, get_columns_sample, initialize_individual_chat, jsonify_prompt, Spinner
from prompts import data_dict_summarizer_prompt

# Only edit here AND filepath under if __name__ == "__main__":
data_dict_summarizer = "qwen2.5:32b-instruct-q8_0-32768"
data_dict_generator = "qwen2.5:32b-instruct-q8_0"

# Common config
llm_base_url = "http://34.204.63.234:11434/v1"
api_key = "none"
model_info =  {
        "vision": False,
        "function_calling": False,
        "json_output": True,
        "family": "Qwen2.5"
    }

# Create reasoning config
# Need to be more creative
data_dict_summarizer_client = OpenAIChatCompletionClient(
    frequency_penalty=0.2, 
    logit_bias=None, 
    max_tokens=128000,
    presence_penalty=0.5, 
    response_format={"type": "json_object"}, 
    seed=42, 
    temperature=0.8, 
    top_p=0.95, 
    model=data_dict_summarizer,
    api_key='none',  
    model_info=model_info, 
    base_url='http://34.204.63.234:11434/v1'
    )

# Just generate the data dict based on obervered facts
data_dict_generator_client = OpenAIChatCompletionClient(
    frequency_penalty=0.4, 
    logit_bias=None, 
    max_tokens=2048, 
    presence_penalty=0.3, 
    response_format={"type": "json_object"},
    seed=42, 
    temperature=0.2, 
    top_p=0.7, 
    model=data_dict_generator,
    api_key='none', 
    model_info=model_info, 
    base_url='http://34.204.63.234:11434/v1')



#######################################################################
#   !!! DONT EDIT BELOW EXCEPT FOR if __name__ == "__main__":   !!!   #
#######################################################################
async def main(results: list):
    # assign each file (task) for each agent
    tasks = [initialize_individual_chat(filename=results[index][0], metadata=results[index][1], data_dict_generator_client=data_dict_generator_client) for index in range(len(results))]

    # Execute all agent chat tasks concurrently, depends on ollama queue
    responses = await asyncio.gather(*tasks)

    # Convert the responses to list of json responses
    json_response, file_name = await jsonify_prompt(responses)

    # Combine json responses with an initial task message
    # initial_task = [TextMessage(content=f"Review the data dictionary generated by the file handling agents.",source="user")]
    # json_response.extend(initial_task)

    # Initialize summarizer agent
    final_agent = AssistantAgent(name="Data_Dictionary_Analytics_Suggester",
                                 model_client=data_dict_summarizer_client,
                                 system_message=data_dict_summarizer_prompt()
    )

    response = await final_agent.on_messages(
            [TextMessage(content=f"{json_response}\n\nReview the above data dictionary.",source="user")], None
        )
    return response.chat_message.content, file_name


if __name__ == "__main__":
    # Set up command line argument parsing
    parser = argparse.ArgumentParser(description='Process files from a specified directory.')
    parser.add_argument('root_path', nargs='?', default='sheets/mysql/', 
                       help='Root path for processing files (default: sheets/mysql/)')
    args = parser.parse_args()

    async def run():
        root = args.root_path
        # Get all filenames that should be processed in the directory
        files: list[str] = os.listdir(path=root)
        
        # Create and run a list of tasks to process each file
        tasks = [get_columns_sample(root, file_name = file) for file in files]
        results = await asyncio.gather(*tasks)

        # Combine the results with the filenames
        results = list(zip(files, results))
        
        # Run the main function
        suggestion, file_name = await main(results)
        with open(file_name, "a") as f:
            f.write("\n\n"+suggestion)
        return file_name

    # Create spinner instance
    spinner = Spinner("Processing data and generating analytics...")
    try:
        spinner.start()
        file_name = asyncio.run(run())
        print("\nOperation completed.")
        print(f"Analytics use cases appended to {file_name}.")
    finally:
        spinner.stop()
