{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python lib\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, Tuple\n",
    "import venv\n",
    "\n",
    "# Autogen-0.4\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.agents._code_executor_agent import CodeExecutorAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Local\n",
    "from prompts import cleaning_reasoning_prompt, cleaning_checking_prompt\n",
    "from utils import CopyFile, LoadDataset, GetDatasetProfile, Spinner\n",
    "\n",
    "# Only edit here AND filepath under if __name__ == \"__main__\":\n",
    "reasoning_model = \"qwen2.5:32b-instruct-q8_0\"\n",
    "coding_model = \"qwen2.5-coder:32b-instruct-q8_0\"\n",
    "\n",
    "# Common config\n",
    "llm_base_url = \"http://34.204.63.234:11434/v1\"\n",
    "api_key = \"none\"\n",
    "capabilities =  {\n",
    "        \"vision\": False,\n",
    "        \"function_calling\": False,\n",
    "        \"json_output\": False\n",
    "    }\n",
    "\n",
    "#######################################################################\n",
    "#   !!! DONT EDIT BELOW EXCEPT FOR if __name__ == \"__main__\":   !!!   #\n",
    "#######################################################################\n",
    "\n",
    "# Reasoning Model Configuration\n",
    "instruct_client_config = OpenAIChatCompletionClient(\n",
    "    model=reasoning_model,\n",
    "    base_url=llm_base_url,\n",
    "    api_key=api_key,\n",
    "    model_capabilities=capabilities\n",
    ")\n",
    "\n",
    "# Coding Model Configuration\n",
    "code_client_config = OpenAIChatCompletionClient(\n",
    "    model=coding_model,\n",
    "    base_url=llm_base_url,\n",
    "    api_key=api_key,\n",
    "    model_capabilities=capabilities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_cleaning_agents(filepath: Path) -> Tuple[AssistantAgent, AssistantAgent, CodeExecutorAgent, AssistantAgent]:\n",
    "    \n",
    "    # tqdm progress bar\n",
    "    with tqdm(total=5,\n",
    "             desc=\"Creating cleaning team agents\",\n",
    "             bar_format='{desc:>30}{postfix: <1} {bar}|{n_fmt:>4}/{total_fmt:<4}',\n",
    "             colour='green') as pbar:\n",
    "        \n",
    "        ### 1.1 Cleaning reasoning agent - 1\n",
    "        async def create_cleaning_reasoning_agent():\n",
    "            cleaning_reasoning_agent = AssistantAgent(\n",
    "                name=\"cleaning_reasoning_agent\",\n",
    "                is_termination_msg='',\n",
    "                model_client=instruct_client_config,\n",
    "                system_message=cleaning_reasoning_prompt(),\n",
    "            )\n",
    "            pbar.update(1)\n",
    "            return cleaning_reasoning_agent\n",
    "        \n",
    "        async def create_cleaning_checker():\n",
    "            cleaning_checker = AssistantAgent(\n",
    "                name=\"cleaning_checker\",\n",
    "                model_client=instruct_client_config,\n",
    "                system_message=cleaning_checking_prompt()\n",
    "            )\n",
    "            pbar.update(1)\n",
    "            return cleaning_checker\n",
    "        \n",
    "        list_of_cleaning_agents = await asyncio.gather(\n",
    "            create_cleaning_reasoning_agent(),\n",
    "            create_cleaning_checker(),\n",
    "        )\n",
    "        return list_of_cleaning_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_cleaning_pipeline(df: pd.DataFrame, data_dict: Dict[str, Any], filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run the complete data cleaning and transformation pipeline\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # cleaning_reasoning_1, cleaning_reason_2, cleaning_coding, code_executor, code_checker\n",
    "        cleaning_team = await create_cleaning_agents(filepath=filepath)\n",
    "        cleaning_team = [cleaning_team[0], cleaning_team[1]]\n",
    "        \n",
    "        # Setup termination conditions\n",
    "        text_term = TextMentionTermination(\"TERMINATE\") # If the text \"TERMINATE\" is mentioned - text\n",
    "        round_term = MaxMessageTermination(5) #n          # If max message reaches n round - round\n",
    "        termination = text_term | round_term            # text OR n round is met\n",
    "\n",
    "        # First phase: Data Cleaning (Reasoning)\n",
    "        cleaning_team_chat = RoundRobinGroupChat(\n",
    "            cleaning_team,\n",
    "            termination_condition=termination,\n",
    "        )\n",
    "        \n",
    "        # prompt imported from .prompts/\n",
    "        cleaning_task = cleaning_reasoning_prompt() + f\"\"\"\n",
    "<dataset_location>\n",
    "    {str(filepath)}\n",
    "</dataset_location>\n",
    "\n",
    "<data_dictionary>\n",
    "    {data_dict}\n",
    "</data_dictionary>\n",
    "\"\"\"\n",
    "\n",
    "        # A loading spinner to know if the code is frozen or not\n",
    "        await Spinner.async_with_spinner(\n",
    "            message=\"Loading: \",\n",
    "            style=\"braille\",\n",
    "            console_class=Console,\n",
    "            coroutine=cleaning_team_chat.run_stream(task=cleaning_task)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         Processing 24 columns  \u001b[32m██████████\u001b[0m|  24/24  \n",
      "             Preparing dataset  \u001b[32m██████████\u001b[0m|   3/3   \n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=3,\n",
    "          desc=\"Preparing dataset\",\n",
    "          bar_format='{desc:>30}{postfix: <1} {bar}|{n_fmt:>4}/{total_fmt:<4}',\n",
    "          colour='green') as pbar:\n",
    "    # Edit file path\n",
    "    test_file = Path(\"../sheets/credit_card_transactions.csv\")\n",
    "    pbar.update(1)\n",
    "    df = LoadDataset(test_file)\n",
    "    pbar.update(1)\n",
    "    # Custom function in utils/ to get data dict in md format\n",
    "    initial_profile = GetDatasetProfile(df, output_format=\"markdown\")\n",
    "    pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Creating cleaning team agents  \u001b[32m████      \u001b[0m|   2/5   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Loading: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "<Data Cleaning Planner>\n",
      "\n",
      "<purpose>\n",
      "    Provide detailed and actionable data cleaning recommendations with domain-aware considerations for each column.\n",
      "</purpose>\n",
      "\n",
      "<instructions>\n",
      "    1. Review the provided data dictionary thoroughly.\n",
      "    2. Analyze data types and their real-world significance.\n",
      "    3. Identify potential data quality issues without limiting to predefined categories, considering:\n",
      "       - Relationships between columns (e.g., geographic data, dates)\n",
      "       - Data type constraints\n",
      "       - Domain-specific valid ranges\n",
      "       - Business logic dependencies\n",
      "       - Any other anomalies or irregularities present in the data\n",
      "    4. FOR EACH IDENTIFIED ISSUE, PROVIDE A SINGLE, EXACT DATA CLEANING TECHNIQUE TO BE USED.\n",
      "       - **Do NOT present multiple options or suggest evaluations.**\n",
      "       - Use concrete methods (e.g., \"Apply the Z-score method to detect and remove outliers beyond 3 standard deviations using NumPy and Pandas\").\n",
      "       - Ensure the technique is directly implementable in Python using standard libraries such as Pandas, NumPy, or Scikit-learn.\n",
      "    5. Provide a **Brief Reason** explaining why the recommended action is necessary.\n",
      "    6. Ensure recommendations are simple, practical, and directly implementable.\n",
      "</instructions>\n",
      "\n",
      "<output_format>\n",
      "    For each column with issues, provide the following details:\n",
      "    1. **Column Name:** Exact name of the column as per the data dictionary.\n",
      "    2. **Issue Type:** Describe the type of data quality issue identified (e.g., Missing Values, Outliers, Inconsistent Data Types, Duplicate Entries, Invalid Formats, etc.).\n",
      "    3. **Recommended Action:** Specify the precise data cleaning technique to address the issue. Use explicit actions compatible with Python libraries (e.g., \"Use `pandas.to_datetime()` to convert string dates to datetime objects\").\n",
      "    4. **Brief Reason:** Provide a concise explanation of why this action is necessary.\n",
      "    5. **Dependencies/Constraints:** Mention any dependencies or constraints relevant to implementing the action [if applicable].\n",
      "</output_format>\n",
      "\n",
      "<output_example>\n",
      "### Column_Name\n",
      "- **Issue Type:** Missing Values\n",
      "- **Recommended Action:** Use `pandas.fillna()` to impute missing values with the median of the column.\n",
      "- **Brief Reason:** Imputing with the median maintains the central tendency without being affected by outliers.\n",
      "- **Dependencies/Constraints:** Ensure that the median imputation aligns with the data distribution and does not distort other related features.\n",
      "\n",
      "---\n",
      "</output_example>\n",
      "\n",
      "<strict_rules>\n",
      "    1. Use EXACT ACTUAL column names as provided in the data dictionary.\n",
      "    2. Only suggest BASIC data cleaning actions that are straightforward to implement.\n",
      "    3. Provide CLEAR and SIMPLE explanations without jargon.\n",
      "    4. Focus on PRACTICAL SOLUTIONS that can be directly translated into code.\n",
      "    5. Ensure all suggestions are RATIONAL and applicable to real-world scenarios.\n",
      "    6. Do NOT ask any questions or seek clarifications.\n",
      "    7. OMIT any Exploratory Data Analysis (EDA) steps and visualizations.\n",
      "    8. Consider and respect relationships between columns (e.g., treat latitude and longitude together).\n",
      "    9. Adhere strictly to data type constraints (e.g., handle categorical vs. continuous data appropriately).\n",
      "    10. **Do NOT provide multiple options, use conditional phrases (e.g., \"if possible\"), or suggest further evaluations. Choose and specify one definitive action for each issue.**\n",
      "</strict_rules>\n",
      "\n",
      "<dataset_location>\n",
      "    ..\\sheets\\credit_card_transactions.csv\n",
      "</dataset_location>\n",
      "\n",
      "<data_dictionary>\n",
      "    \n",
      "# Dataset Profile\n",
      "Total columns: 24\n",
      "\n",
      "## Column Details\n",
      "| Column Name | Data Type | Sample Value | Stats | Additional Info |\n",
      "|------------|-----------|--------------|-------|------------------|\n",
      "| Unnamed: 0 | int64 | 0 | Total: 1296675, Nulls: 0 (0.0%), Unique: 1296675 | Mean: 648337.00<br>Median: 648337.00<br>Range: [0.00, 1296674.00] |\n",
      "| trans_date_trans_time | object | 2019-01-01 00:00:18 | Total: 1296675, Nulls: 0 (0.0%), Unique: 1274791 | - |\n",
      "| cc_num | int64 | 2703186189652095 | Total: 1296675, Nulls: 0 (0.0%), Unique: 983 | Mean: 417192042079726656.00<br>Median: 3521417320836166.00<br>Range: [60416207185.00, 4992346398065154048.00] |\n",
      "| merchant | object | fraud_Rippin, Kub and Mann | Total: 1296675, Nulls: 0 (0.0%), Unique: 693 | - |\n",
      "| category | object | misc_net | Total: 1296675, Nulls: 0 (0.0%), Unique: 14 | - |\n",
      "| amt | float64 | 4.97 | Total: 1296675, Nulls: 0 (0.0%), Unique: 52928 | Mean: 70.35<br>Median: 47.52<br>Range: [1.00, 28948.90] |\n",
      "| first | object | Jennifer | Total: 1296675, Nulls: 0 (0.0%), Unique: 352 | - |\n",
      "| last | object | Banks | Total: 1296675, Nulls: 0 (0.0%), Unique: 481 | - |\n",
      "| gender | object | F | Total: 1296675, Nulls: 0 (0.0%), Unique: 2 | - |\n",
      "| street | object | 561 Perry Cove | Total: 1296675, Nulls: 0 (0.0%), Unique: 983 | - |\n",
      "| city | object | Moravian Falls | Total: 1296675, Nulls: 0 (0.0%), Unique: 894 | - |\n",
      "| state | object | NC | Total: 1296675, Nulls: 0 (0.0%), Unique: 51 | - |\n",
      "| zip | int64 | 28654 | Total: 1296675, Nulls: 0 (0.0%), Unique: 970 | Mean: 48800.67<br>Median: 48174.00<br>Range: [1257.00, 99783.00] |\n",
      "| lat | float64 | 36.08 | Total: 1296675, Nulls: 0 (0.0%), Unique: 968 | Mean: 38.54<br>Median: 39.35<br>Range: [20.03, 66.69] |\n",
      "| long | float64 | -81.18 | Total: 1296675, Nulls: 0 (0.0%), Unique: 969 | Mean: -90.23<br>Median: -87.48<br>Range: [-165.67, -67.95] |\n",
      "| city_pop | int64 | 3495 | Total: 1296675, Nulls: 0 (0.0%), Unique: 879 | Mean: 88824.44<br>Median: 2456.00<br>Range: [23.00, 2906700.00] |\n",
      "| job | object | Psychologist, counselling | Total: 1296675, Nulls: 0 (0.0%), Unique: 494 | - |\n",
      "| dob | object | 1988-03-09 | Total: 1296675, Nulls: 0 (0.0%), Unique: 968 | - |\n",
      "| trans_num | object | 0b242abb623afc578575680df30655b9 | Total: 1296675, Nulls: 0 (0.0%), Unique: 1296675 | - |\n",
      "| unix_time | int64 | 1325376018 | Total: 1296675, Nulls: 0 (0.0%), Unique: 1274823 | Mean: 1349243636.73<br>Median: 1349249747.00<br>Range: [1325376018.00, 1371816817.00] |\n",
      "| merch_lat | float64 | 36.01 | Total: 1296675, Nulls: 0 (0.0%), Unique: 1247805 | Mean: 38.54<br>Median: 39.37<br>Range: [19.03, 67.51] |\n",
      "| merch_long | float64 | -82.05 | Total: 1296675, Nulls: 0 (0.0%), Unique: 1275745 | Mean: -90.23<br>Median: -87.44<br>Range: [-166.67, -66.95] |\n",
      "| is_fraud | int64 | 0 | Total: 1296675, Nulls: 0 (0.0%), Unique: 2 | Mean: 0.01<br>Median: 0.00<br>Range: [0.00, 1.00] |\n",
      "| merch_zipcode | float64 | 28705.00 | Total: 1296675, Nulls: 195973 (15.1%), Unique: 28336 | Mean: 46825.75<br>Median: 45860.00<br>Range: [1001.00, 99403.00] |\n",
      "\n",
      "</data_dictionary>\n",
      "\n",
      "⠋ Loading: ---------- cleaning_reasoning_agent ----------\n",
      "### Data Cleaning Recommendations\n",
      "\n",
      "Based on the provided data dictionary, there are a few columns that require some cleaning and preprocessing steps:\n",
      "\n",
      "#### `dob` Column:\n",
      "The `dob` column is currently in string format (`object`). To efficiently utilize this data for analysis or modeling, it should be converted to a datetime object.\n",
      "\n",
      "- **Step**: Convert the `dob` column from string format to datetime.\n",
      "    ```python\n",
      "    df['dob'] = pd.to_datetime(df['dob'])\n",
      "    ```\n",
      "\n",
      "#### `merch_zipcode` Column:\n",
      "The `merch_zipcode` column has missing values (195,973 null entries).\n",
      "\n",
      "- **Step**: Handle the missing values in the `merch_zipcode` column. Since it's a float column representing zip codes, a reasonable approach would be to fill these nulls with the median or mode value of existing zipcodes.\n",
      "    ```python\n",
      "    # Fill NA values with median (or mode) merch_zipcode\n",
      "    df['merch_zipcode'].fillna(df['merch_zipcode'].median(), inplace=True)\n",
      "    ```\n",
      "\n",
      "### Data Transformation Recommendations\n",
      "\n",
      "#### `dob` Column:\n",
      "After converting the `dob` column to a datetime object, you might want to derive additional features such as age or year of birth.\n",
      "\n",
      "- **Step**: Create new columns for 'Age' and 'Year_of_Birth'.\n",
      "    ```python\n",
      "    import pandas as pd\n",
      "    from datetime import datetime\n",
      "\n",
      "    # Convert `dob` column to datetime format if not done already\n",
      "    df['dob'] = pd.to_datetime(df['dob'])\n",
      "\n",
      "    # Calculate age in years\n",
      "    end_date = datetime.now()\n",
      "    df['Age'] = (end_date - df['dob']).dt.days // 365\n",
      "\n",
      "    # Extract year of birth\n",
      "    df['Year_of_Birth'] = df['dob'].dt.year\n",
      "    ```\n",
      "\n",
      "#### `state` Column:\n",
      "The `state` column, although not necessarily needing cleaning as there are no nulls, could be useful for geospatial analysis. However, consider creating an abbreviation mapping if the full state names were preferred.\n",
      "\n",
      "- **Step**: Create a dictionary mapping two-letter abbreviations to state names if needed.\n",
      "    ```python\n",
      "    # Sample State Abbreviation Mapping (can expand accordingly)\n",
      "    state_map = {\n",
      "        'AL': 'Alabama',\n",
      "        'AK': 'Alaska',\n",
      "        'AZ': 'Arizona',\n",
      "        ...\n",
      "        'NC': 'North Carolina'\n",
      "    }\n",
      "\n",
      "    # Map abbreviations to full names if needed\n",
      "    df['State_Name'] = df['state'].map(state_map)\n",
      "    ```\n",
      "\n",
      "#### `is_fraud` Column:\n",
      "This column identifies fraudulent transactions. If you plan on performing fraud detection, consider balancing the dataset as it is highly imbalanced.\n",
      "\n",
      "- **Step**: Use techniques like SMOTE (Synthetic Minority Over-sampling Technique) to balance classes.\n",
      "    ```python\n",
      "    from imblearn.over_sampling import SMOTE\n",
      "\n",
      "    smote = SMOTE()\n",
      "    X_resampled, y_resampled = smote.fit_resample(X.drop('is_fraud', axis=1), df['is_fraud'])\n",
      "    ```\n",
      "\n",
      "### Summary:\n",
      "- **Convert Date Formats**: Convert the `dob` column to datetime.\n",
      "- **Handle Missing Values**: Fill missing values in the `merch_zipcode` column with median or mode values.\n",
      "- **Feature Engineering**: Derive new features like 'Age' and 'Year_of_Birth'.\n",
      "- **Balance Data (if needed)**: Use techniques like SMOTE if planning on building classification models for fraud detection.\n",
      "\n",
      "These steps will help prepare your dataset for analysis, modeling, and visualization.\n",
      "[Prompt tokens: 2048, Completion tokens: 748]\n",
      "⠸ Loading: ---------- cleaning_checker ----------\n",
      "### Validation Report\n",
      "\n",
      "#### Overall Status:\n",
      "- **Fail**\n",
      "\n",
      "#### Detailed Findings:\n",
      "\n",
      "1. **Column Name:** `dob`\n",
      "   - **Issue Type:** Conversion to datetime object.\n",
      "   - **Status:** Pass\n",
      "   - **Errors/Warnings:** None identified.\n",
      "   - **Suggestions:** No corrections needed.\n",
      "\n",
      "2. **Column Name:** `merch_zipcode`\n",
      "   - **Issue Type:** Handling missing values in float column representing zip codes.\n",
      "   - **Status:** Fail\n",
      "   - **Errors/Warnings:**\n",
      "     1. The recommended action is not a clear, definitive directive due to the phrase \"or mode value of existing zipcodes.\"\n",
      "     2. There are no explicit references to specific Python functions or methods (other than `pandas.fillna`).\n",
      "   - **Suggestions:** \n",
      "     - Rewrite the recommendation to use either median **OR** mode explicitly.\n",
      "     - Add a reference to an exact method from pandas if not already provided.\n",
      "\n",
      "3. **Column Name:** `dob`\n",
      "   - **Issue Type:** Deriving new features such as 'Age' and 'Year_of_Birth'.\n",
      "   - **Status:** Fail\n",
      "   - **Errors/Warnings:**\n",
      "     1. This is a duplicate entry since the `dob` column was already addressed in a previous issue.\n",
      "     2. The recommended action involves multiple steps without a clear separation of distinct issues.\n",
      "   - **Suggestions:**\n",
      "     - Ensure each recommendation for `dob` is handled distinctly and not duplicated.\n",
      "     - Break up the task into specific, actionable recommendations (e.g., separate steps for deriving 'Age' and 'Year_of_Birth').\n",
      "\n",
      "4. **Column Name:** `state`\n",
      "   - **Issue Type:** Creating a dictionary mapping abbreviations to state names.\n",
      "   - **Status:** Fail\n",
      "   - **Errors/Warnings:**\n",
      "     1. No initial issue was identified, yet a transformation recommendation is provided.\n",
      "     2. The action suggests the creation of a new feature (`State_Name`) without aligning with any identified cleaning need according to previous issues.\n",
      "   - **Suggestions:**\n",
      "     - Identify why this change is necessary and frame it as an actual issue if needed.\n",
      "     - Ensure the recommendation aligns properly with identified problems.\n",
      "\n",
      "5. **Column Name:** `is_fraud`\n",
      "   - **Issue Type:** Handling class imbalance for fraud detection.\n",
      "   - **Status:** Fail\n",
      "   - **Errors/Warnings:**\n",
      "     1. Suggesting use of `SMOTE` but no explicit details on the data splitting methodology if this is intended only for modeling or part of general prep.\n",
      "     2. The action includes data not explicitly mentioned (X and y, presumably from a separate preprocessing step).\n",
      "   - **Suggestions:**\n",
      "     - Clarify in what context the resampling with SMOTE would be used (e.g., explicit model training).\n",
      "     - Ensure data handling like splitting into X and Y is clear within the recommendation.\n",
      "\n",
      "### Summary:\n",
      "- There are multiple issues flagged for needing clarifications, reductions, or corrections.\n",
      "- Some recommendations overlap on actions that might not align well with specific initial problem descriptions.\n",
      "- The report requires a more systematic approach to separating distinct cleaning actions and transformations accurately.\n",
      "[Prompt tokens: 1506, Completion tokens: 655]\n",
      "⠇ Loading: ---------- cleaning_reasoning_agent ----------\n",
      "### merch_zipcode\n",
      "- **Issue Type:** Handling missing values in float column representing zip codes.\n",
      "- **Recommended Action:** Use `pandas.fillna()` to impute missing values with the mode value of existing zip codes using `df['merch_zipcode'].fillna(df['merch_zipcode'].mode()[0], inplace=True)`.\n",
      "- **Brief Reason:** The mode is more appropriate for categorical data like zip codes, as it represents the most frequent category.\n",
      "- **Dependencies/Constraints:** Ensure that the mode exists and is meaningful in this context.\n",
      "\n",
      "---\n",
      "\n",
      "### dob\n",
      "- **Issue Type:** Deriving new features such as 'Age'.\n",
      "- **Recommended Action:** Calculate the age by subtracting the year of birth from the current year using `df['Age'] = (pd.to_datetime('now').year - pd.DatetimeIndex(df['dob']).year)`.\n",
      "- **Brief Reason:** Age is a useful derived feature that simplifies time-based calculations and insights.\n",
      "- **Dependencies/Constraints:** Ensure that the dob column has been successfully converted to datetime format.\n",
      "\n",
      "---\n",
      "\n",
      "### dob\n",
      "- **Issue Type:** Deriving new features such as 'Year_of_Birth'.\n",
      "- **Recommended Action:** Extract the year of birth from the `dob` column using `df['Year_of_Birth'] = pd.DatetimeIndex(df['dob']).year`.\n",
      "- **Brief Reason:** Year of Birth can be useful for various age-related analyses and segmentations.\n",
      "- **Dependencies/Constraints:** Ensure that the dob column has been successfully converted to datetime format.\n",
      "\n",
      "---\n",
      "\n",
      "### state\n",
      "- **Issue Type:** Inconsistent use of state abbreviations.\n",
      "- **Recommended Action:** Create a mapping dictionary from state abbreviations to full names and apply it using `df['State_Name'] = df['state'].map({'CA': 'California', 'NY': 'New York', ...})` (populate with all necessary mappings).\n",
      "- **Brief Reason:** Using full state names can prevent misinterpretation and aligns with standard reporting practices.\n",
      "- **Dependencies/Constraints:** Ensure the mapping dictionary covers all existing abbreviations in the dataset.\n",
      "\n",
      "---\n",
      "\n",
      "### is_fraud\n",
      "- **Issue Type:** Handling class imbalance for fraud detection.\n",
      "- **Recommended Action:** Apply SMOTE to balance classes before training a model using `from imblearn.over_sampling import SMOTE; smote = SMOTE(); X_resampled, y_resampled = smote.fit_resample(X, y)` (where X and y are the feature matrix and target vector).\n",
      "- **Brief Reason:** Balancing classes with SMOTE improves model performance on minority classes like fraud.\n",
      "- **Dependencies/Constraints:** Ensure that X and y are correctly defined before applying SMOTE.\n",
      "[Prompt tokens: 1386, Completion tokens: 546]\n",
      "⠧ Loading: ---------- cleaning_checker ----------\n",
      "### Validation Report\n",
      "\n",
      "#### Overall Status:\n",
      "- **Fail**\n",
      "\n",
      "#### Detailed Findings:\n",
      "\n",
      "1. **Column Name:** `merch_zipcode`\n",
      "   - **Issue Type:** Handling missing values in float column representing zip codes.\n",
      "   - **Status:** Pass\n",
      "   - **Errors/Warnings:** None identified.\n",
      "   - **Suggestions:** No corrections needed.\n",
      "\n",
      "2. **Column Name:** `dob`\n",
      "   - **Issue Type (First Instance):** Deriving new features such as 'Age'.\n",
      "   - **Status:** Pass\n",
      "   - **Errors/Warnings:** None identified.\n",
      "   - **Suggestions:** No corrections needed.\n",
      "\n",
      "3. **Column Name:** `dob`\n",
      "   - **Issue Type (Second Instance):** Deriving new features such as 'Year_of_Birth'.\n",
      "   - **Status:** Pass\n",
      "   - **Errors/Warnings:** None identified.\n",
      "   - **Suggestions:** No corrections needed.\n",
      "\n",
      "4. **Column Name:** `state`\n",
      "   - **Issue Type:** Inconsistent use of state abbreviations.\n",
      "   - **Status:** Fail\n",
      "   - **Errors/Warnings:**\n",
      "     1. The recommended action suggests imputing a new column (`State_Name`) without addressing the inconsistency in the original `state` column.\n",
      "   - **Suggestions:**\n",
      "     - Ensure the inconsistencies in the `state` column are resolved directly.\n",
      "     - Optionally, create a new column for full state names if needed.\n",
      "\n",
      "5. **Column Name:** `is_fraud`\n",
      "   - **Issue Type:** Handling class imbalance for fraud detection.\n",
      "   - **Status:** Fail\n",
      "   - **Errors/Warnings:**\n",
      "     1. The recommended action (`X_resampled, y_resampled = smote.fit_resample(X, y)`) assumes the existence of variables `X` and `y`, which should be defined explicitly.\n",
      "   - **Suggestions:**\n",
      "     - Provide a more detailed recommendation on how to prepare `X` and `y` before applying SMOTE.\n",
      "\n",
      "### Summary:\n",
      "- Most recommendations are clear and actionable.\n",
      "- The recommendation for the `state` column needs clarification on handling the original inconsistent data directly rather than just creating a new column.\n",
      "- For the `is_fraud` column, ensure that the prerequisite steps (defining `X` and `y`) are explicitly addressed.\n",
      "\n",
      "#### Updated Recommendations:\n",
      "\n",
      "1. **Column Name:** `merch_zipcode`\n",
      "   - **Issue Type:** Handling missing values in float column representing zip codes.\n",
      "   - **Recommended Action:** Use `pandas.fillna()` to impute missing values with the mode value of existing zip codes using `df['merch_zipcode'].fillna(df['merch_zipcode'].mode()[0], inplace=True)`.\n",
      "   - **Brief Reason:** The mode is more appropriate for categorical data like zip codes, as it represents the most frequent category.\n",
      "   - **Dependencies/Constraints:** Ensure that the mode exists and is meaningful in this context.\n",
      "\n",
      "2. **Column Name:** `dob`\n",
      "   - **Issue Type (First Instance):** Deriving new features such as 'Age'.\n",
      "   - **Recommended Action:** Calculate the age by subtracting the year of birth from the current year using `df['Age'] = (pd.to_datetime('now').year - pd.DatetimeIndex(df['dob']).year)`.\n",
      "   - **Brief Reason:** Age is a useful derived feature that simplifies time-based calculations and insights.\n",
      "   - **Dependencies/Constraints:** Ensure that the dob column has been successfully converted to datetime format.\n",
      "\n",
      "3. **Column Name:** `dob`\n",
      "   - **Issue Type (Second Instance):** Deriving new features such as 'Year_of_Birth'.\n",
      "   - **Recommended Action:** Extract the year of birth from the `dob` column using `df['Year_of_Birth'] = pd.DatetimeIndex(df['dob']).year`.\n",
      "   - **Brief Reason:** Year of Birth can be useful for various age-related analyses and segmentations.\n",
      "   - **Dependencies/Constraints:** Ensure that the dob column has been successfully converted to datetime format.\n",
      "\n",
      "4. **Column Name:** `state`\n",
      "   - **Issue Type:** Inconsistent use of state abbreviations.\n",
      "   - **Recommended Action:** Create a mapping dictionary from state abbreviations to full names and apply it using `df['State_Name'] = df['state'].map({'CA': 'California', 'NY': 'New York', ...})` (populate with all necessary mappings). Additionally, replace the inconsistent values in the original column using `df['state'] = df['state'].map({'CA': 'California', 'NY': 'New York', ...}).fillna(df['state'])`.\n",
      "   - **Brief Reason:** Using full state names can prevent misinterpretation and aligns with standard reporting practices.\n",
      "   - **Dependencies/Constraints:** Ensure the mapping dictionary covers all existing abbreviations in the dataset.\n",
      "\n",
      "5. **Column Name:** `is_fraud`\n",
      "   - **Issue Type:** Handling class imbalance for fraud detection.\n",
      "   - **Recommended Action:** Apply SMOTE to balance classes before training a model using:\n",
      "     ```python\n",
      "     from imblearn.over_sampling import SMOTE\n",
      "\n",
      "     # Assuming df is the DataFrame and 'is_fraud' is the target column\n",
      "     X = df.drop(columns='is_fraud')\n",
      "     y = df['is_fraud']\n",
      "     \n",
      "     smote = SMOTE()\n",
      "     X_resampled, y_resampled = smote.fit_resample(X, y)\n",
      "     ```\n",
      "   - **Brief Reason:** Oversampling the minority class can help improve model performance on unbalanced datasets.\n",
      "   - **Dependencies/Constraints:** Ensure `X` and `y` are correctly defined before applying SMOTE.\n",
      "\n",
      "These updated recommendations ensure that all issues are addressed clearly and comprehensively.\n",
      "[Prompt tokens: 1963, Completion tokens: 1164]\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: Maximum number of messages 5 reached, current message count: 5\n",
      "Total prompt tokens: 6903\n",
      "Total completion tokens: 3113\n",
      "Duration: 176.50 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await run_cleaning_pipeline(df, initial_profile, test_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
