{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python lib\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, Tuple\n",
    "import venv\n",
    "\n",
    "# Autogen-0.4\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.agents._code_executor_agent import CodeExecutorAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.model_context import BufferedChatCompletionContext\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Local\n",
    "from prompts import cleaning_reasoning_prompt, cleaning_checking_prompt\n",
    "from utils import CopyFile, LoadDataset, GetDatasetProfile, Spinner\n",
    "\n",
    "# Only edit here AND filepath under if __name__ == \"__main__\":\n",
    "reasoning_model = \"qwen2.5:32b-instruct-q8_0\"\n",
    "coding_model = \"qwen2.5-coder:32b-instruct-q8_0\"\n",
    "\n",
    "# Common config\n",
    "llm_base_url = \"http://34.204.63.234:11434/v1\"\n",
    "api_key = \"none\"\n",
    "capabilities =  {\n",
    "        \"vision\": False,\n",
    "        \"function_calling\": False,\n",
    "        \"json_output\": False\n",
    "    }\n",
    "\n",
    "#######################################################################\n",
    "#   !!! DONT EDIT BELOW EXCEPT FOR if __name__ == \"__main__\":   !!!   #\n",
    "#######################################################################\n",
    "\n",
    "# Reasoning Model Configuration\n",
    "instruct_client_config = OpenAIChatCompletionClient(\n",
    "    model=reasoning_model,\n",
    "    base_url=llm_base_url,\n",
    "    api_key=api_key,\n",
    "    model_capabilities=capabilities\n",
    ")\n",
    "\n",
    "# Coding Model Configuration\n",
    "code_client_config = OpenAIChatCompletionClient(\n",
    "    model=coding_model,\n",
    "    base_url=llm_base_url,\n",
    "    api_key=api_key,\n",
    "    model_capabilities=capabilities\n",
    ")\n",
    "\n",
    "async def create_cleaning_agents(filepath: Path) -> Tuple[AssistantAgent, AssistantAgent]:\n",
    "    \n",
    "    # tqdm progress bar\n",
    "    with tqdm(total=3,\n",
    "             desc=\"Creating cleaning reasoning team agents\",\n",
    "             bar_format='{desc:>30}{postfix: <1} {bar}|{n_fmt:>4}/{total_fmt:<4}',\n",
    "             colour='green') as pbar:\n",
    "        \n",
    "        ### 1.1 Cleaning reasoning agent - 1\n",
    "        async def create_cleaning_reasoning_1():\n",
    "            Data_Cleaning_Planner = AssistantAgent(\n",
    "                name=\"Data_Cleaning_Planner\",\n",
    "                model_client=instruct_client_config,\n",
    "                system_message=cleaning_reasoning_prompt(filepath),\n",
    "            )\n",
    "            pbar.update(1)\n",
    "            return Data_Cleaning_Planner\n",
    "        \n",
    "        async def create_cleaning_reasoning_2():\n",
    "            Validation_Assistant = AssistantAgent(\n",
    "                name=\"Validation_Assistant\",\n",
    "                model_client=instruct_client_config,\n",
    "                system_message=cleaning_checking_prompt(filepath),\n",
    "            )\n",
    "            pbar.update(1)\n",
    "            return Validation_Assistant\n",
    "        \n",
    "        list_of_cleaning_reasoning_agents = await asyncio.gather(\n",
    "            create_cleaning_reasoning_1(),\n",
    "            create_cleaning_reasoning_2(),\n",
    "        )\n",
    "        pbar.update(1)\n",
    "        return list_of_cleaning_reasoning_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cleaning_reasoning_pipeline(data_dict: Dict[str, Any], filepath: Path):\n",
    "    \"\"\"\n",
    "    Run the complete data cleaning and transformation pipeline\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # cleaning_reasoning_agent, \n",
    "        cleaning_reasoning_team = await create_cleaning_agents(filepath)\n",
    "        # cleaning_team = [cleaning_team[0], cleaning_team[1]]\n",
    "        \n",
    "        # Setup termination conditions\n",
    "        statusu_pass = TextMentionTermination(\"Overall Status: Pass\")\n",
    "        max_round = MaxMessageTermination(5)\n",
    "        termination = statusu_pass | max_round\n",
    "\n",
    "        # First phase: Data Cleaning (Reasoning)\n",
    "        cleaning_team_chat = RoundRobinGroupChat(\n",
    "            cleaning_reasoning_team,\n",
    "            termination_condition=termination,\n",
    "        )\n",
    "        \n",
    "        # Save last n messages\n",
    "        context = BufferedChatCompletionContext(buffer_size=1)\n",
    "        \n",
    "        # # A loading spinner to know if the code is frozen or not\n",
    "        # await Spinner.async_with_spinner(\n",
    "        #     message=\"Loading: \",\n",
    "        #     style=\"braille\",\n",
    "        #     console_class=Console,\n",
    "        #     coroutine=cleaning_team_chat.run_stream(task=cleaning_reasoning_prompt(filepath, data_dict), cancellation_token=None)\n",
    "        # )\n",
    "        # context.add_message(message=)\n",
    "        # print(context)\n",
    "        # # Uncomment below to run the code without spinner\n",
    "        stream = await cleaning_team_chat.run_stream(task=cleaning_reasoning_prompt(filepath, data_dict), cancellation_token=None)\n",
    "        for msg in stream:\n",
    "            context.add_message(message=msg)\n",
    "        return context\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         Processing 24 columns  \u001b[32m██████████\u001b[0m|  24/24  \n",
      "             Preparing dataset  \u001b[32m██████████\u001b[0m|   3/3   \n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=3,\n",
    "              desc=\"Preparing dataset\",\n",
    "              bar_format='{desc:>30}{postfix: <1} {bar}|{n_fmt:>4}/{total_fmt:<4}',\n",
    "              colour='green') as pbar:\n",
    "        # Edit file path\n",
    "        test_file = Path(\"..\\\\sheets\\\\credit_card_transactions.csv\")\n",
    "        pbar.update(1)\n",
    "        df = LoadDataset(test_file)\n",
    "        pbar.update(1)\n",
    "        # Custom function in utils/ to get data dict in markdown/natural language/json format\n",
    "        initial_profile = GetDatasetProfile(df, output_format=\"json\")\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating cleaning reasoning team agents  \u001b[32m██████████\u001b[0m|   3/3   \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "An error occurred: object async_generator can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 34\u001b[0m, in \u001b[0;36mcleaning_reasoning_pipeline\u001b[1;34m(data_dict, filepath)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# # A loading spinner to know if the code is frozen or not\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# await Spinner.async_with_spinner(\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#     message=\"Loading: \",\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# print(context)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# # Uncomment below to run the code without spinner\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m cleaning_team_chat\u001b[38;5;241m.\u001b[39mrun_stream(task\u001b[38;5;241m=\u001b[39mcleaning_reasoning_prompt(filepath, data_dict), cancellation_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m stream:\n",
      "\u001b[1;31mTypeError\u001b[0m: object async_generator can't be used in 'await' expression",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m cleaning_reasoning_pipeline(initial_profile, test_file)\n",
      "Cell \u001b[1;32mIn[30], line 39\u001b[0m, in \u001b[0;36mcleaning_reasoning_pipeline\u001b[1;34m(data_dict, filepath)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: An error occurred: object async_generator can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "await cleaning_reasoning_pipeline(initial_profile, test_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
